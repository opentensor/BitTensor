{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a3386f-2dbf-4ec3-9020-e3c688dbfec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bittensor\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from nuclei.gpt2 import GPT2Nucleus\n",
    "from types import SimpleNamespace\n",
    "from loguru import logger\n",
    "bittensor.__debug_on__ = True\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c8938cd-286d-4624-8838-1d18edc7d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1e1905a-1934-4b1f-9c18-c1be1d0983f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bittensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ce331c0c6fcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMiner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbittensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbittensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEndpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbittensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEndpoint\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# Local info.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ce331c0c6fcc>\u001b[0m in \u001b[0;36mMiner\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMiner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbittensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbittensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEndpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbittensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEndpoint\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# Local info.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bittensor' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class Miner:\n",
    "    def __init__( self, dataset: bittensor.Dataloader, endpoint: bittensor.Endpoint, child: bittensor.Endpoint ):\n",
    "        \n",
    "        # Local info.\n",
    "        self.endpoint = endpoint\n",
    "        \n",
    "        # Child to call forward on.\n",
    "        self.child = child\n",
    "        \n",
    "        # Text dataloader.\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        # Axon RPC server.\n",
    "        # We attach the forward and backward passes to this miner class.\n",
    "        # When this miner recieves a Forward/Backward request it calls these functions\n",
    "        self.axon = bittensor.axon ( \n",
    "            local_port = self.endpoint.port,\n",
    "            forward_callback = self.forward,\n",
    "            backward_callback = self.backward\n",
    "        )\n",
    "        \n",
    "        # Dendrite RPC Client.\n",
    "        # Differentiable RPC function which calls Forward and Backward \n",
    "        # on passes endpoints.\n",
    "        self.dendrite = bittensor.dendrite()\n",
    "        \n",
    "        # Torch NN Module with remote_forward and local_forwadd functions.\n",
    "        # plus a routing function.\n",
    "        self.nucleus = GPT2Nucleus( \n",
    "            routing_callback = self.route \n",
    "        )\n",
    "        \n",
    "        # Base Torch optimizer.\n",
    "        self.optimizer = torch.optim.AdamW(self.nucleus.parameters(), lr = 0.01, betas = (0.9, 0.95) )\n",
    "                \n",
    "    # Function is called by the nucleus to query child and get responses.\n",
    "    def route( self, inputs: torch.int64, query: torch.float32 ) -> torch.float32:\n",
    "        \n",
    "        # Is this a leaf node.\n",
    "        if self.child == None:\n",
    "            response = [torch.zeros( [inputs.shape[0], inputs.shape[1], bittensor.__network_dim__ ])]\n",
    "        \n",
    "        # Otherwise, makes differentiable calls.\n",
    "        else:\n",
    "            # Takes a list of endpoints and a list of inputs\n",
    "            # Sends inputs to endpoints.\n",
    "            responses, return_codes = self.dendrite.forward_text (\n",
    "                endpoints = [self.child], \n",
    "                x = [inputs] \n",
    "            )\n",
    "            \n",
    "        return responses[0]\n",
    "    \n",
    "    # Function which is called when this miner recieves a forward request from a dendrite.\n",
    "    def forward ( self, pubkey:str, inputs: torch.float32, modality:int ) -> torch.FloatTensor:\n",
    "        # Call nucleus (locally, i.e. using the distillation model instead of calling the child)\n",
    "        # return the last hidden layer.  \n",
    "        output = self.nucleus.local_forward (\n",
    "            inputs = inputs        \n",
    "        )\n",
    "        return output.local_hidden\n",
    "\n",
    "    # Function which is called when this miner recieves a backward request. (Off for now.)\n",
    "    def backward ( self, pubkey:str, inputs_x:torch.float32, grads_dy:torch.float32, modality:int ) -> torch.FloatTensor:\n",
    "        return None\n",
    "    \n",
    "    # Start the axon serving endpoint.\n",
    "    def start(self):\n",
    "        self.axon.start()\n",
    "        \n",
    "    # Tear down the axon serving endpoint.\n",
    "    def __del__(self):\n",
    "        self.axon.stop()\n",
    "\n",
    "    # Run a single epoch.\n",
    "    def epoch(self):\n",
    "        # ---- Next Batch ----\n",
    "        for iteration, inputs in enumerate(self.dataset.dataloader( 100 )):     \n",
    "            \n",
    "            # ---- Forward pass ----\n",
    "            output = self.nucleus.remote_forward(\n",
    "                inputs = inputs,\n",
    "                training = True,\n",
    "            )\n",
    "\n",
    "            # ---- Backward pass ----\n",
    "            output.loss = output.local_target_loss + output.distillation_loss + output.remote_target_loss\n",
    "            output.loss.backward() # Accumulates gradients on the nucleus.\n",
    "            self.optimizer.step() # Applies accumulated gradients.\n",
    "            self.optimizer.zero_grad() # Zeros out gradients for next accummulation\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17ce69c4-86bf-4ce5-93d4-0a8310f3c904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO    \u001b[0m|\u001b[36mbittensor._dataloader.dataloader_impl\u001b[0m:\u001b[36mconstruct_text_corpus\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1mRetrieving a dataset file from the IPFS gateway...\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m|\u001b[36mbittensor._dataloader.dataloader_impl\u001b[0m:\u001b[36mconstruct_text_corpus\u001b[0m:\u001b[36m168\u001b[0m - \u001b[1m\u001b[32mAdded:\u001b[0m\u001b[1m \u001b[36mmagna_carta.txt\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m|\u001b[36mbittensor._dataloader.dataloader_impl\u001b[0m:\u001b[36mconstruct_text_corpus\u001b[0m:\u001b[36m168\u001b[0m - \u001b[1m\u001b[32mAdded:\u001b[0m\u001b[1m \u001b[36mmeditations_marcus_aurelius.txt\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m|\u001b[36mbittensor._dataloader.dataloader_impl\u001b[0m:\u001b[36mconstruct_text_corpus\u001b[0m:\u001b[36m168\u001b[0m - \u001b[1m\u001b[32mAdded:\u001b[0m\u001b[1m \u001b[36mrumi.txt\u001b[0m\u001b[1m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Dataset pulled from IPFS\n",
    "dataset = bittensor.dataloader( max_corpus_size = 1000000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04e76c1e-a861-415b-9283-c6ef99ee79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two fake bittensor endpoints for the miners.\n",
    "endpoint_A = bittensor.endpoint( \n",
    "    uid = 0, \n",
    "    hotkey = '0', \n",
    "    ip = '0.0.0.0', \n",
    "    ip_type = 4, \n",
    "    port = 8080 , \n",
    "    modality = 0, \n",
    "    coldkey = 'N/A'\n",
    ")\n",
    "endpoint_B = bittensor.endpoint( \n",
    "    uid = 1, \n",
    "    hotkey = '1', \n",
    "    ip = '0.0.0.0', \n",
    "    ip_type = 4, \n",
    "    port = 8081, \n",
    "    modality = 0, \n",
    "    coldkey = 'N/A'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9fc9575-aab4-4fd0-a2aa-f1b88cde6be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\u001b[32m\u001b[1mSUCCESS \u001b[0m|\u001b[36mbittensor._axon.axon_impl\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m492\u001b[0m - \u001b[32m\u001b[1mAxon has stopped serving on: 127.0.0.1:8080\u001b[0m\n",
      "\u001b[32m\u001b[1mSUCCESS \u001b[0m|\u001b[36mbittensor._axon.axon_impl\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m492\u001b[0m - \u001b[32m\u001b[1mAxon has stopped serving on: 127.0.0.1:8080\u001b[0m\n",
      "\u001b[32m\u001b[1mSUCCESS \u001b[0m|\u001b[36mbittensor._axon.axon_impl\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m492\u001b[0m - \u001b[32m\u001b[1mAxon has stopped serving on: 127.0.0.1:8080\u001b[0m\n",
      "\u001b[32m\u001b[1mSUCCESS \u001b[0m|\u001b[36mbittensor._axon.axon_impl\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m492\u001b[0m - \u001b[32m\u001b[1mAxon has stopped serving on: 127.0.0.1:8080\u001b[0m\n",
      "\u001b[31m\u001b[1mERROR   \u001b[0m|\u001b[36mbittensor._axon.axon_impl\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m478\u001b[0m - \u001b[31m\u001b[1mForward and Backward callbacks must be subscribed on this axon before it starts. Got Forward = None and Backward = None\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Forward and Backward callbacks must be subscribed on this axon before it starts. Got Forward = None and Backward = None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-76aa44d12f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mminer_A\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mminer_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMiner\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint_B\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mminer_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-d06f392ca4b3>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# Start the axon serving endpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Tear down the axon serving endpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/bittensor/bittensor/_axon/axon_impl.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Forward and Backward callbacks must be subscribed on this axon before it starts. Got Forward = {} and Backward = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_server\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Forward and Backward callbacks must be subscribed on this axon before it starts. Got Forward = None and Backward = None"
     ]
    }
   ],
   "source": [
    "# Create and start miner A\n",
    "if \"miner_A\" in locals():\n",
    "    del miner_A\n",
    "    \n",
    "miner_A = Miner( \n",
    "    dataset = dataset, \n",
    "    endpoint = endpoint_A, \n",
    "    child = endpoint_B \n",
    ")\n",
    "\n",
    "miner_A.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "674be448-2de2-4cb0-8c63-4beb788689ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mERROR   \u001b[0m|\u001b[36mbittensor._axon.axon_impl\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m478\u001b[0m - \u001b[31m\u001b[1mForward and Backward callbacks must be subscribed on this axon. Got None and None\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Forward and Backward callbacks must be subscribed on this axon. Got None and None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-652e871c288b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mminer_B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mminer_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMiner\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mminer_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-d06f392ca4b3>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# Start the axon serving endpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Tear down the axon serving endpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/bittensor/bittensor/_axon/axon_impl.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Forward and Backward callbacks must be subscribed on this axon. Got {} and {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_server\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Forward and Backward callbacks must be subscribed on this axon. Got None and None"
     ]
    }
   ],
   "source": [
    "# Create start miner B\n",
    "if \"miner_B\" in locals():\n",
    "    del miner_B\n",
    "    \n",
    "miner_B = Miner(\n",
    "    dataset = dataset, \n",
    "    endpoint = endpoint_B, \n",
    "    child = None \n",
    ")\n",
    "miner_B.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "414eef3e-b2cf-4753-ad75-eb8ddfeb6eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Miner.__del__ at 0x13ba9ed30>\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-10-21b16cd8e160>\", line 70, in __del__\n",
      "AttributeError: 'Miner' object has no attribute 'axon'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mSUCCESS \u001b[0m|\u001b[36mbittensor._axon.axon_impl\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m492\u001b[0m - \u001b[32m\u001b[1mAxon has stopped serving on: 127.0.0.1:8080\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Miner' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c4ec6d2fd73c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Start training miner A.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mminer_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-21b16cd8e160>\u001b[0m in \u001b[0;36mepoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# ---- Forward pass ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             output = self.nucleus.remote_forward(\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/bittensor/nuclei/gpt2.py\u001b[0m in \u001b[0;36mremote_forward\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# remote_context: joined responses from a dendrite.forward_text call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;31m# remote_context.shape = [batch_size, sequence_len (or block_size), bittensor.__network_dim__]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroute\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpooled\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;31m# distillation_loss : distillation loss between local_context and remote_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/bittensor/nuclei/gpt2.py\u001b[0m in \u001b[0;36mroute\u001b[0;34m(self, inputs, query)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The routing function must be set on this nucleus before a remote_forward call can execute.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouting_callback\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_block_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Miner' object is not callable"
     ]
    }
   ],
   "source": [
    "# Start training miner A.\n",
    "miner_A.epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bb4272-06c7-4b4e-b3cc-ff470d91c27d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
